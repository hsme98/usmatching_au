{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b222518e-b8d4-44f7-8759-e74ef01e414c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import argparse\n",
    "\n",
    "import torchvision\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from util import AverageMeter\n",
    "from encoder import SmallAlexNet\n",
    "from align_uniform import align_loss, uniform_loss_prelog\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "import copy\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "class TwoAugUnsupervisedDatasetLbl(torch.utils.data.Dataset):\n",
    "    r\"\"\"Returns two augmentation and no labels.\"\"\"\n",
    "\n",
    "    def __init__(self, dataset, transform, lblmap=None):\n",
    "        self.dataset = dataset\n",
    "        self.transform = transform\n",
    "        self.lblmap = copy.deepcopy(lblmap)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image, lbl = self.dataset[index]\n",
    "        lbl2return = lbl if self.lblmap is None else self.lblmap[lbl]\n",
    "        return self.transform(image), self.transform(image), lbl2return\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "def parse_option():\n",
    "    parser = argparse.ArgumentParser('STL-10 Representation Learning with Alignment and Uniformity Losses')\n",
    "\n",
    "    parser.add_argument('--align_w', type=float, default=1, help='Alignment loss weight')\n",
    "    parser.add_argument('--unif_w', type=float, default=1, help='Uniformity loss weight')\n",
    "    parser.add_argument('--align_alpha', type=float, default=2, help='alpha in alignment loss')\n",
    "    parser.add_argument('--unif_t', type=float, default=2, help='t in uniformity loss')\n",
    "\n",
    "    parser.add_argument('--batch_size', type=int, default=256, help='Batch size')\n",
    "    parser.add_argument('--epochs', type=int, default=200, help='Number of training epochs')\n",
    "    parser.add_argument('--iter', type=int, default=0, help='Number of training epochs')\n",
    "    parser.add_argument('--lr', type=float, default=None,\n",
    "                        help='Learning rate. Default is linear scaling 0.12 per 256 batch size')\n",
    "    parser.add_argument('--lr_decay_rate', type=float, default=0.1, help='Learning rate decay rate')\n",
    "    parser.add_argument('--lr_decay_epochs', default=[155, 170, 185], nargs='*', type=int,\n",
    "                        help='When to decay learning rate')\n",
    "    parser.add_argument('--momentum', type=float, default=0.9, help='SGD momentum')\n",
    "    parser.add_argument('--weight_decay', type=float, default=1e-4, help='L2 weight decay')\n",
    "    parser.add_argument('--feat_dim', type=int, default=128, help='Feature dimensionality')\n",
    "\n",
    "    parser.add_argument('--num_workers', type=int, default=4, help='Number of data loader workers to use')\n",
    "    parser.add_argument('--log_interval', type=int, default=40, help='Number of iterations between logs')\n",
    "    parser.add_argument('--gpus', default=[0], nargs='*', type=int,\n",
    "                        help='List of GPU indices to use, e.g., --gpus 0 1 2 3')\n",
    "\n",
    "    parser.add_argument('--data_folder', type=str, default='./data', help='Path to data')\n",
    "    parser.add_argument('--result_folder', type=str, default='./results', help='Base directory to save model')\n",
    "\n",
    "    opt = parser.parse_args(\"\")\n",
    "\n",
    "    if opt.lr is None:\n",
    "        opt.lr = 0.12 * (opt.batch_size / 256)\n",
    "\n",
    "    opt.gpus = list(map(lambda x: torch.device('cuda', x), opt.gpus))\n",
    "\n",
    "    opt.save_folder = os.path.join(\n",
    "        opt.result_folder,\n",
    "        f\"base_200_sideinformation_align{opt.align_w:g}alpha{opt.align_alpha:g}_unif{opt.unif_w:g}t{opt.unif_t:g}_iter{opt.iter}\"\n",
    "    )\n",
    "    os.makedirs(opt.save_folder, exist_ok=True)\n",
    "\n",
    "    return opt\n",
    "\n",
    "\n",
    "opt = parse_option()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d30d6e3-b6f0-4918-84f9-ec9a134609ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimize: 1 * loss_align(alpha=2) + 1 * loss_uniform(t=2)\n",
      "Files already downloaded and verified\n",
      "Epoch 0/200\tIt 0/20\talign_loss 1.246597 (1.246597)\tuniform_loss -2.628047 (-2.628047)\ttotal_loss -1.381450 (-1.381450)\titer_time 8.195710 (8.195710)\n",
      "Epoch 1/200\tIt 0/20\talign_loss 1.356540 (1.356540)\tuniform_loss -3.444576 (-3.444576)\ttotal_loss -2.088037 (-2.088037)\titer_time 0.787861 (0.787861)\n",
      "Epoch 2/200\tIt 0/20\talign_loss 1.153151 (1.153151)\tuniform_loss -3.463474 (-3.463474)\ttotal_loss -2.310323 (-2.310323)\titer_time 0.743879 (0.743879)\n",
      "Epoch 3/200\tIt 0/20\talign_loss 1.125241 (1.125241)\tuniform_loss -3.552011 (-3.552011)\ttotal_loss -2.426770 (-2.426770)\titer_time 0.779960 (0.779960)\n",
      "Epoch 4/200\tIt 0/20\talign_loss 1.091697 (1.091697)\tuniform_loss -3.556884 (-3.556884)\ttotal_loss -2.465187 (-2.465187)\titer_time 0.708362 (0.708362)\n",
      "Epoch 5/200\tIt 0/20\talign_loss 1.070797 (1.070797)\tuniform_loss -3.595987 (-3.595987)\ttotal_loss -2.525190 (-2.525190)\titer_time 0.921899 (0.921899)\n",
      "Epoch 6/200\tIt 0/20\talign_loss 0.980263 (0.980263)\tuniform_loss -3.597877 (-3.597877)\ttotal_loss -2.617614 (-2.617614)\titer_time 0.744739 (0.744739)\n",
      "Epoch 7/200\tIt 0/20\talign_loss 1.014047 (1.014047)\tuniform_loss -3.592467 (-3.592467)\ttotal_loss -2.578420 (-2.578420)\titer_time 0.968920 (0.968920)\n",
      "Epoch 8/200\tIt 0/20\talign_loss 1.023657 (1.023657)\tuniform_loss -3.617958 (-3.617958)\ttotal_loss -2.594301 (-2.594301)\titer_time 0.733233 (0.733233)\n",
      "Epoch 9/200\tIt 0/20\talign_loss 1.006835 (1.006835)\tuniform_loss -3.614331 (-3.614331)\ttotal_loss -2.607497 (-2.607497)\titer_time 0.803849 (0.803849)\n",
      "Epoch 10/200\tIt 0/20\talign_loss 0.901047 (0.901047)\tuniform_loss -3.627757 (-3.627757)\ttotal_loss -2.726710 (-2.726710)\titer_time 0.744853 (0.744853)\n",
      "Epoch 11/200\tIt 0/20\talign_loss 0.957953 (0.957953)\tuniform_loss -3.631408 (-3.631408)\ttotal_loss -2.673455 (-2.673455)\titer_time 0.940420 (0.940420)\n",
      "Epoch 12/200\tIt 0/20\talign_loss 0.901139 (0.901139)\tuniform_loss -3.634373 (-3.634373)\ttotal_loss -2.733234 (-2.733234)\titer_time 0.723268 (0.723268)\n",
      "Epoch 13/200\tIt 0/20\talign_loss 0.900352 (0.900352)\tuniform_loss -3.623052 (-3.623052)\ttotal_loss -2.722701 (-2.722701)\titer_time 1.003213 (1.003213)\n",
      "Epoch 14/200\tIt 0/20\talign_loss 0.891555 (0.891555)\tuniform_loss -3.644753 (-3.644753)\ttotal_loss -2.753199 (-2.753199)\titer_time 0.736405 (0.736405)\n",
      "Epoch 15/200\tIt 0/20\talign_loss 0.895140 (0.895140)\tuniform_loss -3.645414 (-3.645414)\ttotal_loss -2.750274 (-2.750274)\titer_time 0.996953 (0.996953)\n",
      "Epoch 16/200\tIt 0/20\talign_loss 0.886610 (0.886610)\tuniform_loss -3.652181 (-3.652181)\ttotal_loss -2.765571 (-2.765571)\titer_time 0.738149 (0.738149)\n",
      "Epoch 17/200\tIt 0/20\talign_loss 0.827376 (0.827376)\tuniform_loss -3.647684 (-3.647684)\ttotal_loss -2.820309 (-2.820309)\titer_time 0.884956 (0.884956)\n",
      "Epoch 18/200\tIt 0/20\talign_loss 0.844430 (0.844430)\tuniform_loss -3.646434 (-3.646434)\ttotal_loss -2.802004 (-2.802004)\titer_time 0.718064 (0.718064)\n",
      "Epoch 19/200\tIt 0/20\talign_loss 0.837639 (0.837639)\tuniform_loss -3.654706 (-3.654706)\ttotal_loss -2.817067 (-2.817067)\titer_time 0.814271 (0.814271)\n",
      "Epoch 20/200\tIt 0/20\talign_loss 0.842788 (0.842788)\tuniform_loss -3.667591 (-3.667591)\ttotal_loss -2.824803 (-2.824803)\titer_time 0.731745 (0.731745)\n",
      "Epoch 21/200\tIt 0/20\talign_loss 0.821855 (0.821855)\tuniform_loss -3.649691 (-3.649691)\ttotal_loss -2.827836 (-2.827836)\titer_time 0.959618 (0.959618)\n",
      "Epoch 22/200\tIt 0/20\talign_loss 0.784413 (0.784413)\tuniform_loss -3.646324 (-3.646324)\ttotal_loss -2.861911 (-2.861911)\titer_time 0.732969 (0.732969)\n",
      "Epoch 23/200\tIt 0/20\talign_loss 0.801190 (0.801190)\tuniform_loss -3.655030 (-3.655030)\ttotal_loss -2.853840 (-2.853840)\titer_time 0.887620 (0.887620)\n",
      "Epoch 24/200\tIt 0/20\talign_loss 0.868415 (0.868415)\tuniform_loss -3.662654 (-3.662654)\ttotal_loss -2.794239 (-2.794239)\titer_time 0.837826 (0.837826)\n",
      "Epoch 25/200\tIt 0/20\talign_loss 0.854701 (0.854701)\tuniform_loss -3.672117 (-3.672117)\ttotal_loss -2.817416 (-2.817416)\titer_time 0.880491 (0.880491)\n",
      "Epoch 26/200\tIt 0/20\talign_loss 0.856350 (0.856350)\tuniform_loss -3.659915 (-3.659915)\ttotal_loss -2.803566 (-2.803566)\titer_time 0.765382 (0.765382)\n",
      "Epoch 27/200\tIt 0/20\talign_loss 0.763089 (0.763089)\tuniform_loss -3.657856 (-3.657856)\ttotal_loss -2.894768 (-2.894768)\titer_time 0.995087 (0.995087)\n",
      "Epoch 28/200\tIt 0/20\talign_loss 0.746291 (0.746291)\tuniform_loss -3.662867 (-3.662867)\ttotal_loss -2.916576 (-2.916576)\titer_time 0.733615 (0.733615)\n",
      "Epoch 29/200\tIt 0/20\talign_loss 0.776069 (0.776069)\tuniform_loss -3.651849 (-3.651849)\ttotal_loss -2.875781 (-2.875781)\titer_time 0.974501 (0.974501)\n",
      "Epoch 30/200\tIt 0/20\talign_loss 0.778364 (0.778364)\tuniform_loss -3.668129 (-3.668129)\ttotal_loss -2.889765 (-2.889765)\titer_time 0.818225 (0.818225)\n",
      "Epoch 31/200\tIt 0/20\talign_loss 0.812419 (0.812419)\tuniform_loss -3.682892 (-3.682892)\ttotal_loss -2.870473 (-2.870473)\titer_time 1.015245 (1.015245)\n",
      "Epoch 32/200\tIt 0/20\talign_loss 0.769814 (0.769814)\tuniform_loss -3.662470 (-3.662470)\ttotal_loss -2.892656 (-2.892656)\titer_time 0.823951 (0.823951)\n",
      "Epoch 33/200\tIt 0/20\talign_loss 0.745428 (0.745428)\tuniform_loss -3.682809 (-3.682809)\ttotal_loss -2.937381 (-2.937381)\titer_time 0.963464 (0.963464)\n",
      "Epoch 34/200\tIt 0/20\talign_loss 0.837758 (0.837758)\tuniform_loss -3.686377 (-3.686377)\ttotal_loss -2.848619 (-2.848619)\titer_time 0.711135 (0.711135)\n",
      "Epoch 35/200\tIt 0/20\talign_loss 0.772135 (0.772135)\tuniform_loss -3.672791 (-3.672791)\ttotal_loss -2.900656 (-2.900656)\titer_time 0.940141 (0.940141)\n",
      "Epoch 36/200\tIt 0/20\talign_loss 0.760211 (0.760211)\tuniform_loss -3.673017 (-3.673017)\ttotal_loss -2.912806 (-2.912806)\titer_time 0.759534 (0.759534)\n",
      "Epoch 37/200\tIt 0/20\talign_loss 0.713877 (0.713877)\tuniform_loss -3.671138 (-3.671138)\ttotal_loss -2.957262 (-2.957262)\titer_time 0.990371 (0.990371)\n",
      "Epoch 38/200\tIt 0/20\talign_loss 0.764292 (0.764292)\tuniform_loss -3.682767 (-3.682767)\ttotal_loss -2.918475 (-2.918475)\titer_time 0.740770 (0.740770)\n",
      "Epoch 39/200\tIt 0/20\talign_loss 0.739832 (0.739832)\tuniform_loss -3.689332 (-3.689332)\ttotal_loss -2.949500 (-2.949500)\titer_time 1.003416 (1.003416)\n",
      "Epoch 40/200\tIt 0/20\talign_loss 0.780668 (0.780668)\tuniform_loss -3.674335 (-3.674335)\ttotal_loss -2.893667 (-2.893667)\titer_time 0.738221 (0.738221)\n",
      "Epoch 41/200\tIt 0/20\talign_loss 0.781383 (0.781383)\tuniform_loss -3.692969 (-3.692969)\ttotal_loss -2.911586 (-2.911586)\titer_time 0.866283 (0.866283)\n",
      "Epoch 42/200\tIt 0/20\talign_loss 0.729176 (0.729176)\tuniform_loss -3.675184 (-3.675184)\ttotal_loss -2.946008 (-2.946008)\titer_time 0.822334 (0.822334)\n",
      "Epoch 43/200\tIt 0/20\talign_loss 0.736712 (0.736712)\tuniform_loss -3.680107 (-3.680107)\ttotal_loss -2.943396 (-2.943396)\titer_time 0.898060 (0.898060)\n",
      "Epoch 44/200\tIt 0/20\talign_loss 0.729986 (0.729986)\tuniform_loss -3.667342 (-3.667342)\ttotal_loss -2.937356 (-2.937356)\titer_time 0.797223 (0.797223)\n",
      "Epoch 45/200\tIt 0/20\talign_loss 0.758869 (0.758869)\tuniform_loss -3.684364 (-3.684364)\ttotal_loss -2.925495 (-2.925495)\titer_time 0.986472 (0.986472)\n",
      "Epoch 46/200\tIt 0/20\talign_loss 0.697012 (0.697012)\tuniform_loss -3.675523 (-3.675523)\ttotal_loss -2.978511 (-2.978511)\titer_time 0.862062 (0.862062)\n",
      "Epoch 47/200\tIt 0/20\talign_loss 0.705046 (0.705046)\tuniform_loss -3.678440 (-3.678440)\ttotal_loss -2.973394 (-2.973394)\titer_time 0.990898 (0.990898)\n",
      "Epoch 48/200\tIt 0/20\talign_loss 0.721347 (0.721347)\tuniform_loss -3.687876 (-3.687876)\ttotal_loss -2.966528 (-2.966528)\titer_time 0.796243 (0.796243)\n",
      "Epoch 49/200\tIt 0/20\talign_loss 0.739255 (0.739255)\tuniform_loss -3.681829 (-3.681829)\ttotal_loss -2.942574 (-2.942574)\titer_time 1.004869 (1.004869)\n",
      "Epoch 50/200\tIt 0/20\talign_loss 0.716205 (0.716205)\tuniform_loss -3.692707 (-3.692707)\ttotal_loss -2.976501 (-2.976501)\titer_time 0.727464 (0.727464)\n",
      "Epoch 51/200\tIt 0/20\talign_loss 0.736539 (0.736539)\tuniform_loss -3.684894 (-3.684894)\ttotal_loss -2.948355 (-2.948355)\titer_time 0.969576 (0.969576)\n",
      "Epoch 52/200\tIt 0/20\talign_loss 0.679267 (0.679267)\tuniform_loss -3.698264 (-3.698264)\ttotal_loss -3.018997 (-3.018997)\titer_time 0.759353 (0.759353)\n",
      "Epoch 53/200\tIt 0/20\talign_loss 0.727112 (0.727112)\tuniform_loss -3.686637 (-3.686637)\ttotal_loss -2.959525 (-2.959525)\titer_time 0.816574 (0.816574)\n",
      "Epoch 54/200\tIt 0/20\talign_loss 0.744432 (0.744432)\tuniform_loss -3.703018 (-3.703018)\ttotal_loss -2.958586 (-2.958586)\titer_time 0.872443 (0.872443)\n",
      "Epoch 55/200\tIt 0/20\talign_loss 0.705144 (0.705144)\tuniform_loss -3.691969 (-3.691969)\ttotal_loss -2.986825 (-2.986825)\titer_time 0.978755 (0.978755)\n",
      "Epoch 56/200\tIt 0/20\talign_loss 0.691504 (0.691504)\tuniform_loss -3.690528 (-3.690528)\ttotal_loss -2.999024 (-2.999024)\titer_time 0.749220 (0.749220)\n",
      "Epoch 57/200\tIt 0/20\talign_loss 0.702013 (0.702013)\tuniform_loss -3.687176 (-3.687176)\ttotal_loss -2.985163 (-2.985163)\titer_time 0.845538 (0.845538)\n",
      "Epoch 58/200\tIt 0/20\talign_loss 0.699095 (0.699095)\tuniform_loss -3.685089 (-3.685089)\ttotal_loss -2.985994 (-2.985994)\titer_time 0.732629 (0.732629)\n",
      "Epoch 59/200\tIt 0/20\talign_loss 0.709733 (0.709733)\tuniform_loss -3.704279 (-3.704279)\ttotal_loss -2.994546 (-2.994546)\titer_time 0.918370 (0.918370)\n",
      "Epoch 60/200\tIt 0/20\talign_loss 0.664596 (0.664596)\tuniform_loss -3.699685 (-3.699685)\ttotal_loss -3.035088 (-3.035088)\titer_time 0.729772 (0.729772)\n",
      "Epoch 61/200\tIt 0/20\talign_loss 0.728813 (0.728813)\tuniform_loss -3.707170 (-3.707170)\ttotal_loss -2.978357 (-2.978357)\titer_time 0.931185 (0.931185)\n",
      "Epoch 62/200\tIt 0/20\talign_loss 0.636300 (0.636300)\tuniform_loss -3.691570 (-3.691570)\ttotal_loss -3.055270 (-3.055270)\titer_time 0.940332 (0.940332)\n",
      "Epoch 63/200\tIt 0/20\talign_loss 0.729871 (0.729871)\tuniform_loss -3.704520 (-3.704520)\ttotal_loss -2.974649 (-2.974649)\titer_time 0.968471 (0.968471)\n",
      "Epoch 64/200\tIt 0/20\talign_loss 0.719098 (0.719098)\tuniform_loss -3.702996 (-3.702996)\ttotal_loss -2.983897 (-2.983897)\titer_time 0.788445 (0.788445)\n",
      "Epoch 65/200\tIt 0/20\talign_loss 0.689861 (0.689861)\tuniform_loss -3.707482 (-3.707482)\ttotal_loss -3.017621 (-3.017621)\titer_time 0.852895 (0.852895)\n",
      "Epoch 66/200\tIt 0/20\talign_loss 0.638588 (0.638588)\tuniform_loss -3.701768 (-3.701768)\ttotal_loss -3.063180 (-3.063180)\titer_time 0.740525 (0.740525)\n",
      "Epoch 67/200\tIt 0/20\talign_loss 0.724573 (0.724573)\tuniform_loss -3.718650 (-3.718650)\ttotal_loss -2.994077 (-2.994077)\titer_time 0.775965 (0.775965)\n",
      "Epoch 68/200\tIt 0/20\talign_loss 0.608618 (0.608618)\tuniform_loss -3.696236 (-3.696236)\ttotal_loss -3.087619 (-3.087619)\titer_time 0.971345 (0.971345)\n",
      "Epoch 69/200\tIt 0/20\talign_loss 0.696451 (0.696451)\tuniform_loss -3.713222 (-3.713222)\ttotal_loss -3.016771 (-3.016771)\titer_time 0.741583 (0.741583)\n",
      "Epoch 70/200\tIt 0/20\talign_loss 0.620200 (0.620200)\tuniform_loss -3.695826 (-3.695826)\ttotal_loss -3.075626 (-3.075626)\titer_time 0.895912 (0.895912)\n",
      "Epoch 71/200\tIt 0/20\talign_loss 0.650337 (0.650337)\tuniform_loss -3.697843 (-3.697843)\ttotal_loss -3.047506 (-3.047506)\titer_time 0.899815 (0.899815)\n",
      "Epoch 72/200\tIt 0/20\talign_loss 0.673805 (0.673805)\tuniform_loss -3.686276 (-3.686276)\ttotal_loss -3.012472 (-3.012472)\titer_time 0.780427 (0.780427)\n",
      "Epoch 73/200\tIt 0/20\talign_loss 0.668762 (0.668762)\tuniform_loss -3.715016 (-3.715016)\ttotal_loss -3.046254 (-3.046254)\titer_time 0.723956 (0.723956)\n",
      "Epoch 74/200\tIt 0/20\talign_loss 0.642761 (0.642761)\tuniform_loss -3.710491 (-3.710491)\ttotal_loss -3.067730 (-3.067730)\titer_time 0.968467 (0.968467)\n",
      "Epoch 75/200\tIt 0/20\talign_loss 0.605324 (0.605324)\tuniform_loss -3.703117 (-3.703117)\ttotal_loss -3.097793 (-3.097793)\titer_time 0.721526 (0.721526)\n",
      "Epoch 76/200\tIt 0/20\talign_loss 0.693160 (0.693160)\tuniform_loss -3.712018 (-3.712018)\ttotal_loss -3.018857 (-3.018857)\titer_time 0.882327 (0.882327)\n",
      "Epoch 77/200\tIt 0/20\talign_loss 0.627400 (0.627400)\tuniform_loss -3.707468 (-3.707468)\ttotal_loss -3.080068 (-3.080068)\titer_time 0.724262 (0.724262)\n",
      "Epoch 78/200\tIt 0/20\talign_loss 0.663709 (0.663709)\tuniform_loss -3.720228 (-3.720228)\ttotal_loss -3.056519 (-3.056519)\titer_time 0.960793 (0.960793)\n",
      "Epoch 79/200\tIt 0/20\talign_loss 0.675108 (0.675108)\tuniform_loss -3.713438 (-3.713438)\ttotal_loss -3.038329 (-3.038329)\titer_time 0.761305 (0.761305)\n",
      "Epoch 80/200\tIt 0/20\talign_loss 0.594449 (0.594449)\tuniform_loss -3.709257 (-3.709257)\ttotal_loss -3.114809 (-3.114809)\titer_time 0.751390 (0.751390)\n",
      "Epoch 81/200\tIt 0/20\talign_loss 0.618959 (0.618959)\tuniform_loss -3.704724 (-3.704724)\ttotal_loss -3.085764 (-3.085764)\titer_time 0.722726 (0.722726)\n",
      "Epoch 82/200\tIt 0/20\talign_loss 0.667608 (0.667608)\tuniform_loss -3.714816 (-3.714816)\ttotal_loss -3.047209 (-3.047209)\titer_time 0.775421 (0.775421)\n",
      "Epoch 83/200\tIt 0/20\talign_loss 0.677916 (0.677916)\tuniform_loss -3.713998 (-3.713998)\ttotal_loss -3.036081 (-3.036081)\titer_time 0.787800 (0.787800)\n",
      "Epoch 84/200\tIt 0/20\talign_loss 0.641012 (0.641012)\tuniform_loss -3.701245 (-3.701245)\ttotal_loss -3.060233 (-3.060233)\titer_time 0.974555 (0.974555)\n",
      "Epoch 85/200\tIt 0/20\talign_loss 0.669061 (0.669061)\tuniform_loss -3.727459 (-3.727459)\ttotal_loss -3.058398 (-3.058398)\titer_time 0.775429 (0.775429)\n",
      "Epoch 86/200\tIt 0/20\talign_loss 0.658400 (0.658400)\tuniform_loss -3.715970 (-3.715970)\ttotal_loss -3.057570 (-3.057570)\titer_time 0.950141 (0.950141)\n",
      "Epoch 87/200\tIt 0/20\talign_loss 0.627617 (0.627617)\tuniform_loss -3.723611 (-3.723611)\ttotal_loss -3.095994 (-3.095994)\titer_time 0.751169 (0.751169)\n",
      "Epoch 88/200\tIt 0/20\talign_loss 0.599737 (0.599737)\tuniform_loss -3.710778 (-3.710778)\ttotal_loss -3.111041 (-3.111041)\titer_time 0.856686 (0.856686)\n",
      "Epoch 89/200\tIt 0/20\talign_loss 0.604517 (0.604517)\tuniform_loss -3.711693 (-3.711693)\ttotal_loss -3.107175 (-3.107175)\titer_time 0.787287 (0.787287)\n",
      "Epoch 90/200\tIt 0/20\talign_loss 0.625183 (0.625183)\tuniform_loss -3.717979 (-3.717979)\ttotal_loss -3.092796 (-3.092796)\titer_time 0.837609 (0.837609)\n",
      "Epoch 91/200\tIt 0/20\talign_loss 0.661683 (0.661683)\tuniform_loss -3.715123 (-3.715123)\ttotal_loss -3.053440 (-3.053440)\titer_time 0.732948 (0.732948)\n",
      "Epoch 92/200\tIt 0/20\talign_loss 0.630617 (0.630617)\tuniform_loss -3.708339 (-3.708339)\ttotal_loss -3.077722 (-3.077722)\titer_time 0.987425 (0.987425)\n",
      "Epoch 93/200\tIt 0/20\talign_loss 0.601117 (0.601117)\tuniform_loss -3.716866 (-3.716866)\ttotal_loss -3.115748 (-3.115748)\titer_time 0.690577 (0.690577)\n",
      "Epoch 94/200\tIt 0/20\talign_loss 0.620448 (0.620448)\tuniform_loss -3.719668 (-3.719668)\ttotal_loss -3.099220 (-3.099220)\titer_time 0.950459 (0.950459)\n",
      "Epoch 95/200\tIt 0/20\talign_loss 0.623420 (0.623420)\tuniform_loss -3.708639 (-3.708639)\ttotal_loss -3.085219 (-3.085219)\titer_time 0.900365 (0.900365)\n",
      "Epoch 96/200\tIt 0/20\talign_loss 0.639742 (0.639742)\tuniform_loss -3.728751 (-3.728751)\ttotal_loss -3.089009 (-3.089009)\titer_time 0.962463 (0.962463)\n",
      "Epoch 97/200\tIt 0/20\talign_loss 0.648609 (0.648609)\tuniform_loss -3.731381 (-3.731381)\ttotal_loss -3.082772 (-3.082772)\titer_time 0.828959 (0.828959)\n",
      "Epoch 98/200\tIt 0/20\talign_loss 0.600613 (0.600613)\tuniform_loss -3.713117 (-3.713117)\ttotal_loss -3.112504 (-3.112504)\titer_time 0.987605 (0.987605)\n",
      "Epoch 99/200\tIt 0/20\talign_loss 0.595974 (0.595974)\tuniform_loss -3.725405 (-3.725405)\ttotal_loss -3.129431 (-3.129431)\titer_time 0.741395 (0.741395)\n",
      "Epoch 100/200\tIt 0/20\talign_loss 0.549467 (0.549467)\tuniform_loss -3.705875 (-3.705875)\ttotal_loss -3.156408 (-3.156408)\titer_time 0.968826 (0.968826)\n",
      "Epoch 101/200\tIt 0/20\talign_loss 0.635461 (0.635461)\tuniform_loss -3.733287 (-3.733287)\ttotal_loss -3.097826 (-3.097826)\titer_time 0.755088 (0.755088)\n",
      "Epoch 102/200\tIt 0/20\talign_loss 0.642922 (0.642922)\tuniform_loss -3.714911 (-3.714911)\ttotal_loss -3.071989 (-3.071989)\titer_time 0.985709 (0.985709)\n",
      "Epoch 103/200\tIt 0/20\talign_loss 0.606089 (0.606089)\tuniform_loss -3.724278 (-3.724278)\ttotal_loss -3.118190 (-3.118190)\titer_time 0.812378 (0.812378)\n",
      "Epoch 104/200\tIt 0/20\talign_loss 0.618918 (0.618918)\tuniform_loss -3.724453 (-3.724453)\ttotal_loss -3.105535 (-3.105535)\titer_time 0.912074 (0.912074)\n",
      "Epoch 105/200\tIt 0/20\talign_loss 0.604325 (0.604325)\tuniform_loss -3.715680 (-3.715680)\ttotal_loss -3.111355 (-3.111355)\titer_time 0.838024 (0.838024)\n",
      "Epoch 106/200\tIt 0/20\talign_loss 0.567995 (0.567995)\tuniform_loss -3.726107 (-3.726107)\ttotal_loss -3.158112 (-3.158112)\titer_time 0.996526 (0.996526)\n",
      "Epoch 107/200\tIt 0/20\talign_loss 0.615377 (0.615377)\tuniform_loss -3.714436 (-3.714436)\ttotal_loss -3.099058 (-3.099058)\titer_time 0.791501 (0.791501)\n",
      "Epoch 108/200\tIt 0/20\talign_loss 0.573499 (0.573499)\tuniform_loss -3.715363 (-3.715363)\ttotal_loss -3.141863 (-3.141863)\titer_time 0.968010 (0.968010)\n",
      "Epoch 109/200\tIt 0/20\talign_loss 0.599526 (0.599526)\tuniform_loss -3.731376 (-3.731376)\ttotal_loss -3.131850 (-3.131850)\titer_time 0.736893 (0.736893)\n",
      "Epoch 110/200\tIt 0/20\talign_loss 0.616307 (0.616307)\tuniform_loss -3.733522 (-3.733522)\ttotal_loss -3.117216 (-3.117216)\titer_time 0.926240 (0.926240)\n",
      "Epoch 111/200\tIt 0/20\talign_loss 0.595316 (0.595316)\tuniform_loss -3.726789 (-3.726789)\ttotal_loss -3.131472 (-3.131472)\titer_time 0.710757 (0.710757)\n",
      "Epoch 112/200\tIt 0/20\talign_loss 0.636776 (0.636776)\tuniform_loss -3.718441 (-3.718441)\ttotal_loss -3.081665 (-3.081665)\titer_time 1.010381 (1.010381)\n",
      "Epoch 113/200\tIt 0/20\talign_loss 0.618199 (0.618199)\tuniform_loss -3.733014 (-3.733014)\ttotal_loss -3.114815 (-3.114815)\titer_time 0.738711 (0.738711)\n",
      "Epoch 114/200\tIt 0/20\talign_loss 0.647215 (0.647215)\tuniform_loss -3.723620 (-3.723620)\ttotal_loss -3.076405 (-3.076405)\titer_time 0.920698 (0.920698)\n",
      "Epoch 115/200\tIt 0/20\talign_loss 0.576806 (0.576806)\tuniform_loss -3.714082 (-3.714082)\ttotal_loss -3.137276 (-3.137276)\titer_time 0.729423 (0.729423)\n",
      "Epoch 116/200\tIt 0/20\talign_loss 0.573038 (0.573038)\tuniform_loss -3.732796 (-3.732796)\ttotal_loss -3.159758 (-3.159758)\titer_time 0.830548 (0.830548)\n",
      "Epoch 117/200\tIt 0/20\talign_loss 0.627342 (0.627342)\tuniform_loss -3.740544 (-3.740544)\ttotal_loss -3.113203 (-3.113203)\titer_time 0.721561 (0.721561)\n",
      "Epoch 118/200\tIt 0/20\talign_loss 0.590989 (0.590989)\tuniform_loss -3.727834 (-3.727834)\ttotal_loss -3.136845 (-3.136845)\titer_time 0.868796 (0.868796)\n",
      "Epoch 119/200\tIt 0/20\talign_loss 0.567842 (0.567842)\tuniform_loss -3.729783 (-3.729783)\ttotal_loss -3.161941 (-3.161941)\titer_time 0.717320 (0.717320)\n",
      "Epoch 120/200\tIt 0/20\talign_loss 0.523753 (0.523753)\tuniform_loss -3.722258 (-3.722258)\ttotal_loss -3.198505 (-3.198505)\titer_time 0.952244 (0.952244)\n",
      "Epoch 121/200\tIt 0/20\talign_loss 0.579599 (0.579599)\tuniform_loss -3.728287 (-3.728287)\ttotal_loss -3.148689 (-3.148689)\titer_time 0.729045 (0.729045)\n",
      "Epoch 122/200\tIt 0/20\talign_loss 0.589900 (0.589900)\tuniform_loss -3.727857 (-3.727857)\ttotal_loss -3.137957 (-3.137957)\titer_time 0.878397 (0.878397)\n",
      "Epoch 123/200\tIt 0/20\talign_loss 0.536935 (0.536935)\tuniform_loss -3.725420 (-3.725420)\ttotal_loss -3.188485 (-3.188485)\titer_time 0.772544 (0.772544)\n",
      "Epoch 124/200\tIt 0/20\talign_loss 0.606052 (0.606052)\tuniform_loss -3.716165 (-3.716165)\ttotal_loss -3.110113 (-3.110113)\titer_time 0.970172 (0.970172)\n",
      "Epoch 125/200\tIt 0/20\talign_loss 0.594698 (0.594698)\tuniform_loss -3.725117 (-3.725117)\ttotal_loss -3.130419 (-3.130419)\titer_time 0.731116 (0.731116)\n",
      "Epoch 126/200\tIt 0/20\talign_loss 0.546340 (0.546340)\tuniform_loss -3.725690 (-3.725690)\ttotal_loss -3.179350 (-3.179350)\titer_time 1.015860 (1.015860)\n",
      "Epoch 127/200\tIt 0/20\talign_loss 0.556430 (0.556430)\tuniform_loss -3.732611 (-3.732611)\ttotal_loss -3.176182 (-3.176182)\titer_time 0.944857 (0.944857)\n",
      "Epoch 128/200\tIt 0/20\talign_loss 0.610025 (0.610025)\tuniform_loss -3.735830 (-3.735830)\ttotal_loss -3.125805 (-3.125805)\titer_time 1.022225 (1.022225)\n",
      "Epoch 129/200\tIt 0/20\talign_loss 0.575420 (0.575420)\tuniform_loss -3.731376 (-3.731376)\ttotal_loss -3.155957 (-3.155957)\titer_time 0.747494 (0.747494)\n",
      "Epoch 130/200\tIt 0/20\talign_loss 0.534360 (0.534360)\tuniform_loss -3.712214 (-3.712214)\ttotal_loss -3.177855 (-3.177855)\titer_time 0.968387 (0.968387)\n",
      "Epoch 131/200\tIt 0/20\talign_loss 0.554490 (0.554490)\tuniform_loss -3.733840 (-3.733840)\ttotal_loss -3.179351 (-3.179351)\titer_time 0.780592 (0.780592)\n",
      "Epoch 132/200\tIt 0/20\talign_loss 0.558822 (0.558822)\tuniform_loss -3.734004 (-3.734004)\ttotal_loss -3.175183 (-3.175183)\titer_time 0.916684 (0.916684)\n",
      "Epoch 133/200\tIt 0/20\talign_loss 0.579344 (0.579344)\tuniform_loss -3.726506 (-3.726506)\ttotal_loss -3.147162 (-3.147162)\titer_time 0.838084 (0.838084)\n",
      "Epoch 134/200\tIt 0/20\talign_loss 0.607867 (0.607867)\tuniform_loss -3.740770 (-3.740770)\ttotal_loss -3.132903 (-3.132903)\titer_time 0.991803 (0.991803)\n",
      "Epoch 135/200\tIt 0/20\talign_loss 0.531949 (0.531949)\tuniform_loss -3.721614 (-3.721614)\ttotal_loss -3.189665 (-3.189665)\titer_time 0.918795 (0.918795)\n",
      "Epoch 136/200\tIt 0/20\talign_loss 0.573028 (0.573028)\tuniform_loss -3.737458 (-3.737458)\ttotal_loss -3.164430 (-3.164430)\titer_time 1.022733 (1.022733)\n",
      "Epoch 137/200\tIt 0/20\talign_loss 0.567120 (0.567120)\tuniform_loss -3.735816 (-3.735816)\ttotal_loss -3.168696 (-3.168696)\titer_time 0.731730 (0.731730)\n",
      "Epoch 138/200\tIt 0/20\talign_loss 0.560407 (0.560407)\tuniform_loss -3.731681 (-3.731681)\ttotal_loss -3.171273 (-3.171273)\titer_time 0.964833 (0.964833)\n",
      "Epoch 139/200\tIt 0/20\talign_loss 0.595506 (0.595506)\tuniform_loss -3.739465 (-3.739465)\ttotal_loss -3.143959 (-3.143959)\titer_time 0.839063 (0.839063)\n",
      "Epoch 140/200\tIt 0/20\talign_loss 0.543518 (0.543518)\tuniform_loss -3.731417 (-3.731417)\ttotal_loss -3.187899 (-3.187899)\titer_time 0.962353 (0.962353)\n",
      "Epoch 141/200\tIt 0/20\talign_loss 0.528980 (0.528980)\tuniform_loss -3.727381 (-3.727381)\ttotal_loss -3.198401 (-3.198401)\titer_time 0.756975 (0.756975)\n",
      "Epoch 142/200\tIt 0/20\talign_loss 0.591272 (0.591272)\tuniform_loss -3.746927 (-3.746927)\ttotal_loss -3.155655 (-3.155655)\titer_time 1.017263 (1.017263)\n",
      "Epoch 143/200\tIt 0/20\talign_loss 0.552801 (0.552801)\tuniform_loss -3.723157 (-3.723157)\ttotal_loss -3.170356 (-3.170356)\titer_time 0.756188 (0.756188)\n",
      "Epoch 144/200\tIt 0/20\talign_loss 0.630868 (0.630868)\tuniform_loss -3.731872 (-3.731872)\ttotal_loss -3.101004 (-3.101004)\titer_time 0.981875 (0.981875)\n",
      "Epoch 145/200\tIt 0/20\talign_loss 0.601144 (0.601144)\tuniform_loss -3.734068 (-3.734068)\ttotal_loss -3.132925 (-3.132925)\titer_time 0.800483 (0.800483)\n",
      "Epoch 146/200\tIt 0/20\talign_loss 0.552791 (0.552791)\tuniform_loss -3.733087 (-3.733087)\ttotal_loss -3.180296 (-3.180296)\titer_time 1.022971 (1.022971)\n",
      "Epoch 147/200\tIt 0/20\talign_loss 0.524384 (0.524384)\tuniform_loss -3.730960 (-3.730960)\ttotal_loss -3.206575 (-3.206575)\titer_time 0.717425 (0.717425)\n",
      "Epoch 148/200\tIt 0/20\talign_loss 0.528010 (0.528010)\tuniform_loss -3.724816 (-3.724816)\ttotal_loss -3.196806 (-3.196806)\titer_time 0.972996 (0.972996)\n",
      "Epoch 149/200\tIt 0/20\talign_loss 0.534522 (0.534522)\tuniform_loss -3.736145 (-3.736145)\ttotal_loss -3.201623 (-3.201623)\titer_time 0.881155 (0.881155)\n",
      "Epoch 150/200\tIt 0/20\talign_loss 0.574486 (0.574486)\tuniform_loss -3.723145 (-3.723145)\ttotal_loss -3.148659 (-3.148659)\titer_time 0.893196 (0.893196)\n",
      "Epoch 151/200\tIt 0/20\talign_loss 0.570522 (0.570522)\tuniform_loss -3.742123 (-3.742123)\ttotal_loss -3.171600 (-3.171600)\titer_time 0.865255 (0.865255)\n",
      "Epoch 152/200\tIt 0/20\talign_loss 0.576953 (0.576953)\tuniform_loss -3.744877 (-3.744877)\ttotal_loss -3.167924 (-3.167924)\titer_time 0.969005 (0.969005)\n",
      "Epoch 153/200\tIt 0/20\talign_loss 0.577402 (0.577402)\tuniform_loss -3.719488 (-3.719488)\ttotal_loss -3.142086 (-3.142086)\titer_time 0.807584 (0.807584)\n",
      "Epoch 154/200\tIt 0/20\talign_loss 0.563545 (0.563545)\tuniform_loss -3.736281 (-3.736281)\ttotal_loss -3.172736 (-3.172736)\titer_time 0.983205 (0.983205)\n",
      "Epoch 155/200\tIt 0/20\talign_loss 0.559988 (0.559988)\tuniform_loss -3.721537 (-3.721537)\ttotal_loss -3.161549 (-3.161549)\titer_time 0.748037 (0.748037)\n",
      "Epoch 156/200\tIt 0/20\talign_loss 0.551042 (0.551042)\tuniform_loss -3.761819 (-3.761819)\ttotal_loss -3.210777 (-3.210777)\titer_time 0.992193 (0.992193)\n",
      "Epoch 157/200\tIt 0/20\talign_loss 0.514423 (0.514423)\tuniform_loss -3.740674 (-3.740674)\ttotal_loss -3.226251 (-3.226251)\titer_time 0.905508 (0.905508)\n",
      "Epoch 158/200\tIt 0/20\talign_loss 0.509673 (0.509673)\tuniform_loss -3.743934 (-3.743934)\ttotal_loss -3.234261 (-3.234261)\titer_time 0.971624 (0.971624)\n",
      "Epoch 159/200\tIt 0/20\talign_loss 0.548056 (0.548056)\tuniform_loss -3.753112 (-3.753112)\ttotal_loss -3.205056 (-3.205056)\titer_time 0.748098 (0.748098)\n",
      "Epoch 160/200\tIt 0/20\talign_loss 0.506365 (0.506365)\tuniform_loss -3.746138 (-3.746138)\ttotal_loss -3.239773 (-3.239773)\titer_time 1.012037 (1.012037)\n",
      "Epoch 161/200\tIt 0/20\talign_loss 0.531032 (0.531032)\tuniform_loss -3.745060 (-3.745060)\ttotal_loss -3.214028 (-3.214028)\titer_time 0.872240 (0.872240)\n",
      "Epoch 162/200\tIt 0/20\talign_loss 0.523794 (0.523794)\tuniform_loss -3.766427 (-3.766427)\ttotal_loss -3.242632 (-3.242632)\titer_time 0.927863 (0.927863)\n",
      "Epoch 163/200\tIt 0/20\talign_loss 0.516079 (0.516079)\tuniform_loss -3.747990 (-3.747990)\ttotal_loss -3.231911 (-3.231911)\titer_time 0.805786 (0.805786)\n",
      "Epoch 164/200\tIt 0/20\talign_loss 0.586935 (0.586935)\tuniform_loss -3.750128 (-3.750128)\ttotal_loss -3.163194 (-3.163194)\titer_time 0.929088 (0.929088)\n",
      "Epoch 165/200\tIt 0/20\talign_loss 0.533453 (0.533453)\tuniform_loss -3.756459 (-3.756459)\ttotal_loss -3.223006 (-3.223006)\titer_time 0.717741 (0.717741)\n",
      "Epoch 166/200\tIt 0/20\talign_loss 0.499480 (0.499480)\tuniform_loss -3.741348 (-3.741348)\ttotal_loss -3.241868 (-3.241868)\titer_time 0.934365 (0.934365)\n",
      "Epoch 167/200\tIt 0/20\talign_loss 0.524510 (0.524510)\tuniform_loss -3.755246 (-3.755246)\ttotal_loss -3.230736 (-3.230736)\titer_time 0.707958 (0.707958)\n",
      "Epoch 168/200\tIt 0/20\talign_loss 0.541641 (0.541641)\tuniform_loss -3.743773 (-3.743773)\ttotal_loss -3.202132 (-3.202132)\titer_time 0.984521 (0.984521)\n",
      "Epoch 169/200\tIt 0/20\talign_loss 0.491424 (0.491424)\tuniform_loss -3.748832 (-3.748832)\ttotal_loss -3.257409 (-3.257409)\titer_time 0.733088 (0.733088)\n",
      "Epoch 170/200\tIt 0/20\talign_loss 0.524665 (0.524665)\tuniform_loss -3.759517 (-3.759517)\ttotal_loss -3.234851 (-3.234851)\titer_time 0.949831 (0.949831)\n",
      "Epoch 171/200\tIt 0/20\talign_loss 0.481329 (0.481329)\tuniform_loss -3.752655 (-3.752655)\ttotal_loss -3.271327 (-3.271327)\titer_time 0.737285 (0.737285)\n",
      "Epoch 172/200\tIt 0/20\talign_loss 0.563498 (0.563498)\tuniform_loss -3.755131 (-3.755131)\ttotal_loss -3.191633 (-3.191633)\titer_time 0.975921 (0.975921)\n",
      "Epoch 173/200\tIt 0/20\talign_loss 0.501625 (0.501625)\tuniform_loss -3.750494 (-3.750494)\ttotal_loss -3.248869 (-3.248869)\titer_time 0.753449 (0.753449)\n",
      "Epoch 174/200\tIt 0/20\talign_loss 0.509200 (0.509200)\tuniform_loss -3.747995 (-3.747995)\ttotal_loss -3.238796 (-3.238796)\titer_time 0.907115 (0.907115)\n",
      "Epoch 175/200\tIt 0/20\talign_loss 0.529258 (0.529258)\tuniform_loss -3.749645 (-3.749645)\ttotal_loss -3.220387 (-3.220387)\titer_time 0.730559 (0.730559)\n",
      "Epoch 176/200\tIt 0/20\talign_loss 0.548775 (0.548775)\tuniform_loss -3.758356 (-3.758356)\ttotal_loss -3.209581 (-3.209581)\titer_time 0.970914 (0.970914)\n",
      "Epoch 177/200\tIt 0/20\talign_loss 0.525626 (0.525626)\tuniform_loss -3.724839 (-3.724839)\ttotal_loss -3.199213 (-3.199213)\titer_time 0.726472 (0.726472)\n",
      "Epoch 178/200\tIt 0/20\talign_loss 0.514664 (0.514664)\tuniform_loss -3.753908 (-3.753908)\ttotal_loss -3.239244 (-3.239244)\titer_time 0.771055 (0.771055)\n",
      "Epoch 179/200\tIt 0/20\talign_loss 0.499464 (0.499464)\tuniform_loss -3.751533 (-3.751533)\ttotal_loss -3.252069 (-3.252069)\titer_time 0.690786 (0.690786)\n",
      "Epoch 180/200\tIt 0/20\talign_loss 0.526352 (0.526352)\tuniform_loss -3.761286 (-3.761286)\ttotal_loss -3.234934 (-3.234934)\titer_time 0.922678 (0.922678)\n",
      "Epoch 181/200\tIt 0/20\talign_loss 0.577805 (0.577805)\tuniform_loss -3.764864 (-3.764864)\ttotal_loss -3.187059 (-3.187059)\titer_time 0.789105 (0.789105)\n",
      "Epoch 182/200\tIt 0/20\talign_loss 0.528405 (0.528405)\tuniform_loss -3.746460 (-3.746460)\ttotal_loss -3.218055 (-3.218055)\titer_time 0.896276 (0.896276)\n",
      "Epoch 183/200\tIt 0/20\talign_loss 0.520671 (0.520671)\tuniform_loss -3.754571 (-3.754571)\ttotal_loss -3.233900 (-3.233900)\titer_time 0.719481 (0.719481)\n",
      "Epoch 184/200\tIt 0/20\talign_loss 0.540522 (0.540522)\tuniform_loss -3.750860 (-3.750860)\ttotal_loss -3.210338 (-3.210338)\titer_time 0.977414 (0.977414)\n",
      "Epoch 185/200\tIt 0/20\talign_loss 0.523145 (0.523145)\tuniform_loss -3.747590 (-3.747590)\ttotal_loss -3.224446 (-3.224446)\titer_time 0.740893 (0.740893)\n",
      "Epoch 186/200\tIt 0/20\talign_loss 0.533514 (0.533514)\tuniform_loss -3.757439 (-3.757439)\ttotal_loss -3.223925 (-3.223925)\titer_time 0.901871 (0.901871)\n",
      "Epoch 187/200\tIt 0/20\talign_loss 0.477108 (0.477108)\tuniform_loss -3.754174 (-3.754174)\ttotal_loss -3.277066 (-3.277066)\titer_time 0.786017 (0.786017)\n",
      "Epoch 188/200\tIt 0/20\talign_loss 0.563278 (0.563278)\tuniform_loss -3.741114 (-3.741114)\ttotal_loss -3.177836 (-3.177836)\titer_time 0.920991 (0.920991)\n",
      "Epoch 189/200\tIt 0/20\talign_loss 0.541006 (0.541006)\tuniform_loss -3.758694 (-3.758694)\ttotal_loss -3.217688 (-3.217688)\titer_time 0.727705 (0.727705)\n",
      "Epoch 190/200\tIt 0/20\talign_loss 0.493344 (0.493344)\tuniform_loss -3.755877 (-3.755877)\ttotal_loss -3.262533 (-3.262533)\titer_time 0.999502 (0.999502)\n",
      "Epoch 191/200\tIt 0/20\talign_loss 0.506916 (0.506916)\tuniform_loss -3.751735 (-3.751735)\ttotal_loss -3.244819 (-3.244819)\titer_time 0.726028 (0.726028)\n",
      "Epoch 192/200\tIt 0/20\talign_loss 0.532606 (0.532606)\tuniform_loss -3.752052 (-3.752052)\ttotal_loss -3.219445 (-3.219445)\titer_time 0.976141 (0.976141)\n",
      "Epoch 193/200\tIt 0/20\talign_loss 0.513419 (0.513419)\tuniform_loss -3.748007 (-3.748007)\ttotal_loss -3.234587 (-3.234587)\titer_time 0.723167 (0.723167)\n",
      "Epoch 194/200\tIt 0/20\talign_loss 0.570369 (0.570369)\tuniform_loss -3.755174 (-3.755174)\ttotal_loss -3.184805 (-3.184805)\titer_time 0.984096 (0.984096)\n",
      "Epoch 195/200\tIt 0/20\talign_loss 0.478613 (0.478613)\tuniform_loss -3.746810 (-3.746810)\ttotal_loss -3.268198 (-3.268198)\titer_time 0.721826 (0.721826)\n",
      "Epoch 196/200\tIt 0/20\talign_loss 0.484505 (0.484505)\tuniform_loss -3.757466 (-3.757466)\ttotal_loss -3.272961 (-3.272961)\titer_time 0.964683 (0.964683)\n",
      "Epoch 197/200\tIt 0/20\talign_loss 0.542509 (0.542509)\tuniform_loss -3.755468 (-3.755468)\ttotal_loss -3.212959 (-3.212959)\titer_time 0.762122 (0.762122)\n",
      "Epoch 198/200\tIt 0/20\talign_loss 0.518854 (0.518854)\tuniform_loss -3.748114 (-3.748114)\ttotal_loss -3.229260 (-3.229260)\titer_time 0.908258 (0.908258)\n",
      "Epoch 199/200\tIt 0/20\talign_loss 0.574537 (0.574537)\tuniform_loss -3.754575 (-3.754575)\ttotal_loss -3.180037 (-3.180037)\titer_time 0.746049 (0.746049)\n",
      "Saved to ./results/base_200_sideinformation_align1alpha2_unif1t2_iter0/encoder.pth\n"
     ]
    }
   ],
   "source": [
    "transform = torchvision.transforms.Compose([\n",
    "        torchvision.transforms.RandomResizedCrop(64, scale=(0.08, 1)),\n",
    "        torchvision.transforms.RandomHorizontalFlip(),\n",
    "        torchvision.transforms.ColorJitter(0.4, 0.4, 0.4, 0.4),\n",
    "        torchvision.transforms.RandomGrayscale(p=0.2),\n",
    "        torchvision.transforms.ToTensor(),\n",
    "        torchvision.transforms.Normalize(\n",
    "            (0.44087801806139126, 0.42790631331699347, 0.3867879370752931),\n",
    "            (0.26826768628079806, 0.2610450402318512, 0.26866836876860795),\n",
    "        ),\n",
    "    ])\n",
    "\n",
    "old_lbls = list(range(10))\n",
    "labels_2_keep = [0,1]\n",
    "\n",
    "old2new = {}\n",
    "count = 0\n",
    "for old_lbl in old_lbls:\n",
    "    if old_lbl in labels_2_keep: \n",
    "        old2new[old_lbl] = count\n",
    "        count += 1\n",
    "\n",
    "for old_lbl in old_lbls:\n",
    "    if old_lbl not in labels_2_keep: \n",
    "        old2new[old_lbl] = count\n",
    "\n",
    "new_lbls = list(range(count+1))\n",
    "\n",
    "def get_data_loader(opt):\n",
    "    transform = torchvision.transforms.Compose([\n",
    "        torchvision.transforms.RandomResizedCrop(64, scale=(0.08, 1)),\n",
    "        torchvision.transforms.RandomHorizontalFlip(),\n",
    "        torchvision.transforms.ColorJitter(0.4, 0.4, 0.4, 0.4),\n",
    "        torchvision.transforms.RandomGrayscale(p=0.2),\n",
    "        torchvision.transforms.ToTensor(),\n",
    "        torchvision.transforms.Normalize(\n",
    "            (0.44087801806139126, 0.42790631331699347, 0.3867879370752931),\n",
    "            (0.26826768628079806, 0.2610450402318512, 0.26866836876860795),\n",
    "        ),\n",
    "    ])\n",
    "    dataset = TwoAugUnsupervisedDatasetLbl(\n",
    "        torchvision.datasets.STL10(opt.data_folder, 'train', download=True), \n",
    "        transform=transform, \n",
    "        lblmap=old2new )\n",
    "    \n",
    "    return torch.utils.data.DataLoader(dataset, batch_size=opt.batch_size, num_workers=opt.num_workers,\n",
    "                                       shuffle=True, pin_memory=True)\n",
    "\n",
    "\n",
    "print(f'Optimize: {opt.align_w:g} * loss_align(alpha={opt.align_alpha:g}) + {opt.unif_w:g} * loss_uniform(t={opt.unif_t:g})')\n",
    "\n",
    "torch.cuda.set_device(opt.gpus[0])\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "encoder = SmallAlexNet(feat_dim=opt.feat_dim).to(opt.gpus[0])\n",
    "\n",
    "optim = torch.optim.SGD(encoder.parameters(), lr=opt.lr,\n",
    "                        momentum=opt.momentum, weight_decay=opt.weight_decay)\n",
    "scheduler = torch.optim.lr_scheduler.MultiStepLR(optim, gamma=opt.lr_decay_rate,\n",
    "                                                 milestones=opt.lr_decay_epochs)\n",
    "\n",
    "loader = get_data_loader(opt)\n",
    "align_meter = AverageMeter('align_loss')\n",
    "unif_meter = AverageMeter('uniform_loss')\n",
    "loss_meter = AverageMeter('total_loss')\n",
    "it_time_meter = AverageMeter('iter_time')\n",
    "\n",
    "for epoch in range(opt.epochs):\n",
    "    align_meter.reset()\n",
    "    unif_meter.reset()\n",
    "    loss_meter.reset()\n",
    "    it_time_meter.reset()\n",
    "    t0 = time.time()\n",
    "    for ii, (im_x, im_y, lbl) in enumerate(loader):\n",
    "        optim.zero_grad()\n",
    "        x, y = encoder(torch.cat([im_x.to(opt.gpus[0]), im_y.to(opt.gpus[0])])).chunk(2)\n",
    "        \n",
    "        align_loss_val = align_loss(x, y, alpha=opt.align_alpha)\n",
    "        # group according to new_lbls\n",
    "\n",
    "        z = torch.cat( [x, y])\n",
    "        lbl_z = torch.cat([lbl, lbl])\n",
    "        unif_losses = torch.cat([uniform_loss_prelog(z[lbl_z==new_lbl]) for new_lbl in new_lbls])\n",
    "        unif_loss_val = torch.log( torch.mean(unif_losses) )\n",
    "        \n",
    "        loss = align_loss_val * opt.align_w + unif_loss_val * opt.unif_w\n",
    "        align_meter.update(align_loss_val, x.shape[0])\n",
    "        unif_meter.update(unif_loss_val)\n",
    "        loss_meter.update(loss, x.shape[0])\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        it_time_meter.update(time.time() - t0)\n",
    "        if ii % opt.log_interval == 0:\n",
    "            print(f\"Epoch {epoch}/{opt.epochs}\\tIt {ii}/{len(loader)}\\t\" +\n",
    "                  f\"{align_meter}\\t{unif_meter}\\t{loss_meter}\\t{it_time_meter}\")\n",
    "        t0 = time.time()\n",
    "    scheduler.step()\n",
    "\n",
    "ckpt_file = os.path.join(opt.save_folder, 'encoder.pth')\n",
    "torch.save(encoder.state_dict(), ckpt_file)\n",
    "print(f'Saved to {ckpt_file}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "46dfeed1-b6e6-4cb3-a96b-68fa78bcf010",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n    Here we  do the linear evaluation, the old labels are provided to the linear objective as one hot\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    Here we  do the linear evaluation, the old labels are provided to the linear objective as one hot\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "00c18248-7d9a-4388-a6e3-e3304ba5f363",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetModifiedLbl(torch.utils.data.Dataset):\n",
    "    r\"\"\"Returns two augmentation and no labels.\"\"\"\n",
    "\n",
    "    def __init__(self, dataset, transform, lblmap=None):\n",
    "        self.dataset = dataset\n",
    "        self.transform = transform\n",
    "        self.lblmap = copy.deepcopy(lblmap)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image, lbl = self.dataset[index]\n",
    "        lbl2return = lbl if self.lblmap is None else self.lblmap[lbl]\n",
    "        return self.transform(image), lbl2return\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "42651724-4da3-439f-b35d-f15b322ebc46",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetModifiedLblandLbl(torch.utils.data.Dataset):\n",
    "    r\"\"\"Returns two augmentation and no labels.\"\"\"\n",
    "\n",
    "    def __init__(self, dataset, transform, lblmap):\n",
    "        self.dataset = dataset\n",
    "        self.transform = transform\n",
    "        self.lblmap = copy.deepcopy(lblmap)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image, lbl = self.dataset[index]\n",
    "        return self.transform(image), self.lblmap[lbl], lbl\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bb10fe91-33c3-4ee2-b5b7-d3f1011380de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_loaders(opt):\n",
    "    train_transform = torchvision.transforms.Compose([\n",
    "        torchvision.transforms.RandomResizedCrop(64, scale=(0.08, 1)),\n",
    "        torchvision.transforms.ToTensor(),\n",
    "        torchvision.transforms.Normalize(\n",
    "            (0.44087801806139126, 0.42790631331699347, 0.3867879370752931),\n",
    "            (0.26826768628079806, 0.2610450402318512, 0.26866836876860795),\n",
    "        ),\n",
    "        torchvision.transforms.RandomHorizontalFlip()\n",
    "    ])\n",
    "    val_transform = torchvision.transforms.Compose([\n",
    "        torchvision.transforms.Resize(70),\n",
    "        torchvision.transforms.CenterCrop(64),\n",
    "        torchvision.transforms.ToTensor(),\n",
    "        torchvision.transforms.Normalize(\n",
    "            (0.44087801806139126, 0.42790631331699347, 0.3867879370752931),\n",
    "            (0.26826768628079806, 0.2610450402318512, 0.26866836876860795),\n",
    "        ),\n",
    "    ])\n",
    "    train_dataset = DatasetModifiedLblandLbl( torchvision.datasets.STL10(opt.data_folder, 'train', download=True, transform=train_transform) )\n",
    "    val_dataset =  DatasetModifiedLblandLbl( torchvision.datasets.STL10(opt.data_folder, 'test', transform=val_transform) )\n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=opt.batch_size,\n",
    "                                               num_workers=opt.num_workers, shuffle=True, pin_memory=True)\n",
    "    val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=opt.batch_size,\n",
    "                                             num_workers=opt.num_workers, pin_memory=True)\n",
    "    return train_loader, val_loader\n",
    "\n",
    "\n",
    "def validate(opt, encoder, classifier, val_loader):\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels_mod, labels_act in val_loader:\n",
    "            pred = classifier( (torch.cat( encoder(images.to(opt.gpus[0]), layer_index=opt.layer_index).flatten(1), torch.nn.functional.one_hot(labels_mod.to(opt.gpus[0])), dim=1)).argmax(dim=1)\n",
    "            correct += (pred.cpu() == labels).sum().item()\n",
    "    return correct / len(val_loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "146282ba-d904-4d56-ae75-491417d7eb3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt.gpu=opt.gpus[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8502ae3-aed1-4150-b1be-9ae1f1d3f8e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b0e8d1a-d5f1-4580-9ad6-37b38c2827ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = parse_option()\n",
    "\n",
    "opt.gpu=opt.gpus[0]\n",
    "torch.cuda.set_device(opt.gpus)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "encoder = SmallAlexNet(feat_dim=opt.feat_dim).to(opt.gpus[0])\n",
    "encoder.eval()\n",
    "train_loader, val_loader = get_data_loaders(opt)\n",
    "\n",
    "with torch.no_grad():\n",
    "    sample, _ = train_loader.dataset[0]\n",
    "    eval_numel = encoder(sample.unsqueeze(0).to(opt.gpus[0]), layer_index=opt.layer_index).numel()\n",
    "print(f'Feature dimension: {eval_numel}')\n",
    "\n",
    "try:\n",
    "    encoder.load_state_dict(torch.load(opt.encoder_checkpoint, map_location=opt.gpus[0]))\n",
    "except TypeError:\n",
    "    try:\n",
    "        encoder = torch.load(opt.encoder_checkpoint)[-1].to(opt.gpus[0]).module\n",
    "    except:\n",
    "        encoder = torch.load(opt.encoder_checkpoint)[-1].to(opt.gpus[0])\n",
    "print(f'Loaded checkpoint from {opt.encoder_checkpoint}')\n",
    "\n",
    "classifier = nn.Linear(eval_numel, 10).to(opt.gpus[0])\n",
    "\n",
    "optim = torch.optim.Adam(classifier.parameters(), lr=opt.lr, betas=(0.5, 0.999))\n",
    "scheduler = torch.optim.lr_scheduler.MultiStepLR(optim, gamma=opt.lr_decay_rate,\n",
    "                                                 milestones=opt.lr_decay_epochs)\n",
    "\n",
    "loss_meter = AverageMeter('loss')\n",
    "it_time_meter = AverageMeter('iter_time')\n",
    "for epoch in range(opt.epochs):\n",
    "    loss_meter.reset()\n",
    "    it_time_meter.reset()\n",
    "    t0 = time.time()\n",
    "    for ii, (images, labels_mod, labels) in enumerate(train_loader):\n",
    "        optim.zero_grad()\n",
    "        with torch.no_grad():\n",
    "            feats = encoder(images.to(opt.gpus[0]), layer_index=opt.layer_index).flatten(1)\n",
    "        logits = classifier(torch.cat(feats, torch.nn.functional.one_hot(labels_mod.to(opt.gpus[0])),dim=1))\n",
    "        loss = F.cross_entropy(logits, labels.to(opt.gpus[0]))\n",
    "        loss_meter.update(loss, images.shape[0])\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        it_time_meter.update(time.time() - t0)\n",
    "        if ii % opt.log_interval == 0:\n",
    "            print(f\"Epoch {epoch}/{opt.epochs}\\tIt {ii}/{len(train_loader)}\\t{loss_meter}\\t{it_time_meter}\")\n",
    "        t0 = time.time()\n",
    "    scheduler.step()\n",
    "    val_acc = validate(opt, encoder, classifier, val_loader)\n",
    "    print(f\"Epoch {epoch}/{opt.epochs}\\tval_acc {val_acc*100:.4g}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c621110-8122-4466-8731-bbfccb6193b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "usmatching_env",
   "language": "python",
   "name": "usmatching_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
